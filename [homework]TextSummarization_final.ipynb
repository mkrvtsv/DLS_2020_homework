{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Kmb8UhIzOnfK"
   },
   "source": [
    "# Text Summarization. Homework\n",
    "\n",
    "Всем привет! Это домашка по суммаризации текста.\n",
    "\n",
    "На семинаре мы рассмотрели базовые модели для суммаризации текста. Попробуйте теперь улучшить два метода: TextRank и Extractive RNN. Задание достаточно большое и требует хорошую фантазию, тут можно эксперементировать во всю.\n",
    "\n",
    "Для сдачи заданий надо получить определенное качество по test-у:\n",
    "\n",
    "- 1 задание: 0.27 BLEU\n",
    "- 2 задание: 0.3 BLEU\n",
    "\n",
    "Если ваш подход пробивает это качество – задание считается пройденным. Плюсом будет описание того, почему вы решили использовать то или иное решение. \n",
    "\n",
    "Датасет: gazeta.ru\n",
    "\n",
    "**P.S.** Возможно, в датасете находятся пустые данные. Проверьте эту гипотезу, и если надо, сделайте предобратоку датасета.\n",
    "\n",
    "\n",
    "`Ноутбук создан на основе семинара Гусева Ильи на кафедре компьютерной лингвистики МФТИ.`\n",
    "\n",
    "Загрузим датасет и необходимые библиотеки"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "OqkLTkFRfXvA"
   },
   "outputs": [],
   "source": [
    "!wget -q https://www.dropbox.com/s/43l702z5a5i2w8j/gazeta_train.txt\n",
    "!wget -q https://www.dropbox.com/s/k2egt3sug0hb185/gazeta_val.txt\n",
    "!wget -q https://www.dropbox.com/s/3gki5n5djs9w0v6/gazeta_test.txt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "SXS1sdYZCluU"
   },
   "outputs": [],
   "source": [
    "!pip install --upgrade razdel allennlp torch fasttext OpenNMT-py networkx pymorphy2 nltk rouge==0.3.1 summa\n",
    "!pip install transformers youtokentome catalyst\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "5pZ2UGS2DGjH"
   },
   "outputs": [],
   "source": [
    "import random\n",
    "import pandas as pd\n",
    "\n",
    "def read_gazeta_records(file_name, shuffle=True, sort_by_date=False):\n",
    "    assert shuffle != sort_by_date\n",
    "    records = []\n",
    "    with open(file_name, \"r\") as r:\n",
    "        for line in r:\n",
    "            records.append(eval(line)) # Simple hack\n",
    "    records = pd.DataFrame(records)\n",
    "    if sort_by_date:\n",
    "        records = records.sort(\"date\")\n",
    "    if shuffle:\n",
    "        records = records.sample(frac=1)\n",
    "    return records\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "GNDp-BunEA91"
   },
   "outputs": [],
   "source": [
    "train_records = read_gazeta_records(\"gazeta_train.txt\")\n",
    "val_records = read_gazeta_records(\"gazeta_val.txt\")\n",
    "test_records = read_gazeta_records(\"gazeta_test.txt\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 293
    },
    "colab_type": "code",
    "id": "6eXU23zG-Z57",
    "outputId": "5a850535-bb8f-4c1b-ddaf-b25956fa89fb"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>url</th>\n",
       "      <th>text</th>\n",
       "      <th>title</th>\n",
       "      <th>summary</th>\n",
       "      <th>date</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>13402</th>\n",
       "      <td>https://www.gazeta.ru/sport/2018/06/05/a_11788...</td>\n",
       "      <td>Сборная России сыграла вничью (1:1) с командой...</td>\n",
       "      <td>«Сборная России похожа на пианиста без практики»</td>\n",
       "      <td>Сборная России сыграла вничью в товарищеском м...</td>\n",
       "      <td>2018-06-05 23:16:52</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34512</th>\n",
       "      <td>https://www.gazeta.ru/sport/2012/09/17/a_47747...</td>\n",
       "      <td>Форвард «Каролины» Александр Семин может переж...</td>\n",
       "      <td>«Локомотив» ждет Семина</td>\n",
       "      <td>Форвард «Каролины» Александр Семин на время ло...</td>\n",
       "      <td>2012-09-17 09:43:51</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5955</th>\n",
       "      <td>https://www.gazeta.ru/sport/2019/02/25/a_12207...</td>\n",
       "      <td>Одни из сильнейших фигуристок России Евгения М...</td>\n",
       "      <td>«Времени не было»: Медведеву могут оставить бе...</td>\n",
       "      <td>Федерация фигурного катания на коньках России ...</td>\n",
       "      <td>2019-02-25 19:28:16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21974</th>\n",
       "      <td>https://www.gazeta.ru/sport/2012/08/02/a_47067...</td>\n",
       "      <td>В стрельбе наступает пора дабл-трэпа, где выст...</td>\n",
       "      <td>Комова и Мустафина ждут реванша</td>\n",
       "      <td>В четверг на Олимпиаде за медали в многоборье ...</td>\n",
       "      <td>2012-08-02 07:20:39</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33112</th>\n",
       "      <td>https://www.gazeta.ru/culture/2015/09/02/a_773...</td>\n",
       "      <td>В среду, 2 сентября, на YouTube-канале мультсе...</td>\n",
       "      <td>«Машу и Медведя» заменят страшилки</td>\n",
       "      <td>2 сентября вышла последняя серия мультипликаци...</td>\n",
       "      <td>2015-09-02 20:04:35</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                     url  ...                 date\n",
       "13402  https://www.gazeta.ru/sport/2018/06/05/a_11788...  ...  2018-06-05 23:16:52\n",
       "34512  https://www.gazeta.ru/sport/2012/09/17/a_47747...  ...  2012-09-17 09:43:51\n",
       "5955   https://www.gazeta.ru/sport/2019/02/25/a_12207...  ...  2019-02-25 19:28:16\n",
       "21974  https://www.gazeta.ru/sport/2012/08/02/a_47067...  ...  2012-08-02 07:20:39\n",
       "33112  https://www.gazeta.ru/culture/2015/09/02/a_773...  ...  2015-09-02 20:04:35\n",
       "\n",
       "[5 rows x 5 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# глянем на дата-сеты\n",
    "\n",
    "train_records.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "RMJKOAXLAbBa",
    "outputId": "2c933e9f-0106-4b91-f2a6-014ba54cb05a"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((52400, 5), (5265, 5), (5770, 5))"
      ]
     },
     "execution_count": 6,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_records.shape, val_records.shape, test_records.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 295
    },
    "colab_type": "code",
    "id": "21S25O0V6wUL",
    "outputId": "a80e6d5a-59f3-4778-9e89-2b94c9a45724"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(url        0\n",
       " text       0\n",
       " title      0\n",
       " summary    0\n",
       " date       0\n",
       " dtype: int64, url        0\n",
       " text       0\n",
       " title      0\n",
       " summary    0\n",
       " date       0\n",
       " dtype: int64, url        0\n",
       " text       0\n",
       " title      0\n",
       " summary    0\n",
       " date       0\n",
       " dtype: int64)"
      ]
     },
     "execution_count": 7,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_records.isna().sum(), val_records.isna().sum(), test_records.isna().sum()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "HFVFswtN-Rw3",
    "outputId": "3d33c48d-9a26-4673-c431-109fe983a22d"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 8,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_records.text.apply(lambda x: True if x=='' else False).sum()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "QsAcVSli3r3S"
   },
   "source": [
    "## 1 задание: TextRank (порог: 0.27 BLEU)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "c7jAQp-_Ds98"
   },
   "source": [
    "TextRank - unsupervised метод для составления кратких выжимок из текста. \n",
    "Описание метода:\n",
    "\n",
    "1. Сплитим текст по предложениям\n",
    "2. Считаем \"похожесть\" предложений между собой\n",
    "3. Строим граф предложений с взвешенными ребрами\n",
    "4. С помощью алгоритм PageRank получаем наиболее важные предложения, на основе которых делаем summary.\n",
    "\n",
    "Функция похожести можно сделать и из нейросетевых(или около) моделек: FastText, ELMO и BERT. Выберете один метод, загрузите предобученную модель и с ее помощью для каждого предложениия сделайте sentence embedding. С помощью косинусной меры определяйте похожесть предложений.\n",
    "\n",
    "Предобученные модели можно взять по [ссылке](http://docs.deeppavlov.ai/en/master/features/pretrained_vectors.html)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Aig2FMJoeOQW"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import transformers\n",
    "from tqdm import tqdm\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from catalyst.utils import set_global_seed\n",
    "\n",
    "seed = 383\n",
    "set_global_seed(seed)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "lGaF0FTuh9Wt",
    "outputId": "f5ede65d-d96b-4153-d943-03eb1374b9f3"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([[0.99493668]]), array([[0.63636364]]), array([[-1.]]))"
      ]
     },
     "execution_count": 13,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cosine_similarity([[1,2,3,4,5]], [[2,3,4,5,6]]), cosine_similarity([[1,2,3,4,5]], [[5,4,3,2,1]]), cosine_similarity([[1,1]], [[-1,-1]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000,
     "referenced_widgets": [
      "52f5c0a6764843c1ab94aaae1ab141c0",
      "207f17d2d4b14a3ea2152d7f218178e5",
      "510ba48686a5409d978c5476538a4949",
      "e8c0c6b9322444d3a0eea04b25729c28",
      "db078a74d1994f53973fa06af7ce8981",
      "a54684bc3a1249488dcfc8c502afea11",
      "cf02a69dd113471fa5dbbcd3a78712b1",
      "e5138e7a20394f3f8aba4a47a0dc32d5",
      "a8202956ebf64de9a69c11b6ef7ecd23",
      "add6c0103cff42a295f4ee4d914e0c0d",
      "5a93df56b1814b918805d4afb68f8745",
      "4631e9af312e4bc9b91287a4312ca5c8",
      "8ca17c2bf19147738fd3c7b57e355315",
      "d161a3f94d61497a847c2387351c4d82",
      "e43aec4ccb594486bf3eade8d89b7b2f",
      "af9cfb21b60f4e13a309ef108693d88e",
      "1a6241e1bddd4889b29aaa487108d99a",
      "adad49b14a3846a6a58bf6da21eed356",
      "4356a6a39fb64fbba42ec6a7373cc666",
      "ca11129007c846faba5aa6eddf246c8b",
      "187731a5070d48c9a963da3553d8b1c6",
      "8745e42d4987443a85813077bc68b675",
      "b6f52783e7ad4260a62b83a4180b0096",
      "2833541725a94c25969a3577cc530e24",
      "f6588cb521f1475993791d73339089f5",
      "e9dbceb0226e48fd8e082f30d5b74598",
      "c663e3433edf4bddbab170c965c0bc8d",
      "603320f156a54ac1b62d916b101b7f6d",
      "476e4553b28641f799db9704d2dbbe25",
      "28daeb2fc17c4428b3f23a195b0b3c8c",
      "c5e44a8d4b4b45b9a8c61fc957bbdb1b",
      "677699f9452148afb9a906766c59984e",
      "73bd49f2621e4629a4fc896079a4cc76",
      "44defe717cf747fe9f330841a8388a78",
      "1cfbfdb3ed4846c8bf3c9627d2030e4a",
      "7412c847046645159e89a186b2df6d0a",
      "9d7e701f928041a6b7552c41f791f483",
      "b28d3502559b498f8dc9c6a91e30b29f",
      "3cbb33ac3a4b4759b1ee0dce6c7ff0ad",
      "81785dd999c24fbd89a98b04ed5c5d37"
     ]
    },
    "colab_type": "code",
    "id": "H_nX7QjGGMZm",
    "outputId": "066fb021-d976-419e-f6db-0dd5ff328f87"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "52f5c0a6764843c1ab94aaae1ab141c0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=642.0, style=ProgressStyle(description_…"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a8202956ebf64de9a69c11b6ef7ecd23",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=1649718.0, style=ProgressStyle(descript…"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1a6241e1bddd4889b29aaa487108d99a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=112.0, style=ProgressStyle(description_…"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f6588cb521f1475993791d73339089f5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=24.0, style=ProgressStyle(description_w…"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "73bd49f2621e4629a4fc896079a4cc76",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=711456784.0, style=ProgressStyle(descri…"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "BertForMaskedLM(\n",
       "  (bert): BertModel(\n",
       "    (embeddings): BertEmbeddings(\n",
       "      (word_embeddings): Embedding(119547, 768, padding_idx=0)\n",
       "      (position_embeddings): Embedding(512, 768)\n",
       "      (token_type_embeddings): Embedding(2, 768)\n",
       "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (encoder): BertEncoder(\n",
       "      (layer): ModuleList(\n",
       "        (0): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (1): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (2): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (3): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (4): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (5): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (6): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (7): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (8): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (9): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (10): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (11): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (pooler): BertPooler(\n",
       "      (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "      (activation): Tanh()\n",
       "    )\n",
       "  )\n",
       "  (cls): BertOnlyMLMHead(\n",
       "    (predictions): BertLMPredictionHead(\n",
       "      (transform): BertPredictionHeadTransform(\n",
       "        (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "      )\n",
       "      (decoder): Linear(in_features=768, out_features=119547, bias=True)\n",
       "    )\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 14,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# загрузим предварительно обученные модели лля токенизации и получения эмбеддингов\n",
    "\n",
    "pretrained_model_name = \"DeepPavlov/rubert-base-cased-sentence\"\n",
    "tokenizer = transformers.AutoTokenizer.from_pretrained(pretrained_model_name)\n",
    "model = transformers.AutoModelWithLMHead.from_pretrained(pretrained_model_name)\n",
    "\n",
    "model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "73gW6_OuQYUw"
   },
   "outputs": [],
   "source": [
    "def embed_str(sentence):\n",
    "    '''\n",
    "    Функция для вывода массива эмбедингов предложения, полученных с пом. \n",
    "    модели BERT. Эти эмбединги - выход скрытого слоя модели.\n",
    "    '''\n",
    "\n",
    "    input_ids = torch.tensor(tokenizer.encode(sentence)).unsqueeze(0)\n",
    "    outputs = model(input_ids)\n",
    "    last_hidden_states = [outputs[0].detach().numpy().squeeze()[-1, :]]\n",
    "\n",
    "    return last_hidden_states\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 86
    },
    "colab_type": "code",
    "id": "8CZB8Cwe3XLB",
    "outputId": "a1893d53-4272-472c-be38-b6c5c1a6e219"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/lib/python3.6/importlib/_bootstrap.py:219: RuntimeWarning:\n",
      "\n",
      "numpy.ufunc size changed, may indicate binary incompatibility. Expected 192 from C header, got 216 from PyObject\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from nltk.translate.bleu_score import corpus_bleu\n",
    "from rouge import Rouge\n",
    "\n",
    "def calc_scores(references, predictions, metric=\"all\"):\n",
    "    print(\"Count:\", len(predictions))\n",
    "    print(\"Ref:\", references[-1])\n",
    "    print(\"Hyp:\", predictions[-1])\n",
    "\n",
    "    if metric in (\"bleu\", \"all\"):\n",
    "        print(\"BLEU: \", corpus_bleu([[r] for r in references], predictions))\n",
    "    if metric in (\"rouge\", \"all\"):\n",
    "        rouge = Rouge()\n",
    "        scores = rouge.get_scores(predictions, references, avg=True)\n",
    "        print(\"ROUGE: \", scores)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from itertools import combinations\n",
    "import networkx as nx\n",
    "import numpy as np\n",
    "import pymorphy2\n",
    "\n",
    "import razdel\n",
    "\n",
    "# Используйте эту штуку как бэйзлайн\n",
    "def unique_words_similarity(words1, words2):\n",
    "    '''\n",
    "    Функция подсчёта близости предложений на основе пересечения слов\n",
    "    ''' \n",
    "    words1 = set(words1)\n",
    "    words2 = set(words2)\n",
    "    if not len(words1) or not len(words2):\n",
    "        return 0.0\n",
    "    return len(words1.intersection(words2))/(np.log10(len(words1)) + np.log10(len(words2)))\n",
    "\n",
    "def your_super_words_similarity(words1, words2):\n",
    "\n",
    "    # Your code\n",
    "    dist = cosine_similarity(words1, words2)[:, 0]\n",
    "    return dist[0]\n",
    "\n",
    "def gen_text_rank_summary(text, calc_similarity=unique_words_similarity, summary_part=0.1, lower=True, morph=None):\n",
    "    '''\n",
    "    Составление summary с помощью TextRank\n",
    "    '''\n",
    "    # Разбиваем текст на предложения\n",
    "    sentences = [sentence.text for sentence in razdel.sentenize(text)]\n",
    "    n_sentences = len(sentences)\n",
    "\n",
    "    # Токенизируем предложения\n",
    "    sentences_words = [[token.text.lower() if lower else token.text for token in razdel.tokenize(sentence)] for sentence in sentences]\n",
    "\n",
    "    # При необходимости лемматизируем слова\n",
    "    if morph is not None:\n",
    "        sentences_words = [[morph.parse(word)[0].normal_form for word in words] for words in sentences_words]\n",
    "\n",
    "    # Для каждой пары предложений считаем близость\n",
    "    pairs = combinations(range(n_sentences), 2)\n",
    "    if calc_similarity==unique_words_similarity:\n",
    "        scores = [(i, j, calc_similarity(sentences_words[i], sentences_words[j])) for i, j in pairs]\n",
    "    else:\n",
    "        '''\n",
    "        скор для варианта с рассчетом косинусного расстояния м-ду эмбеддингами\n",
    "        переведём sentences_words в эмбединги\n",
    "        '''\n",
    "        embeded_words = [embed_str(words) for words in sentences_words]\n",
    "        # print(1)\n",
    "        scores = [(i, j, calc_similarity(embeded_words[i], embeded_words[j])) for i, j in pairs]\n",
    "\n",
    "    # Строим граф с рёбрами, равными близости между предложениями\n",
    "    g = nx.Graph()\n",
    "    g.add_weighted_edges_from(scores)\n",
    "\n",
    "    # Считаем PageRank\n",
    "    pr = nx.pagerank(g)\n",
    "    result = [(i, pr[i], s) for i, s in enumerate(sentences) if i in pr]\n",
    "    result.sort(key=lambda x: x[1], reverse=True)\n",
    "\n",
    "    # Выбираем топ предложений\n",
    "    n_summary_sentences = max(int(n_sentences * summary_part), 1)\n",
    "    result = result[:n_summary_sentences]\n",
    "\n",
    "    # Восстанавливаем оригинальный их порядок\n",
    "    result.sort(key=lambda x: x[0])\n",
    "\n",
    "    # Восстанавливаем текст выжимки\n",
    "    predicted_summary = \" \".join([sentence for i, proba, sentence in result])\n",
    "    predicted_summary = predicted_summary.lower() if lower else predicted_summary\n",
    "    return predicted_summary\n",
    "\n",
    "def calc_text_rank_score(records, calc_similarity=unique_words_similarity, summary_part=0.1, lower=True, nrows=1000, morph=None):\n",
    "    references = []\n",
    "    predictions = []\n",
    "\n",
    "    for text, summary in tqdm(records[['text', 'summary']].values[:nrows]):\n",
    "        summary = summary if not lower else summary.lower()\n",
    "        references.append(summary)\n",
    "\n",
    "        predicted_summary = gen_text_rank_summary(text, calc_similarity, summary_part, lower, morph=morph)\n",
    "        text = text if not lower else text.lower()\n",
    "        predictions.append(predicted_summary)\n",
    "\n",
    "    calc_scores(references, predictions)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 280
    },
    "colab_type": "code",
    "id": "m2GwyRrMPAzS",
    "outputId": "2767be3f-67d7-4474-c8ff-c4dcb03c33c4"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1000/1000 [00:39<00:00, 25.25it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Count: 1000\n",
      "Ref: 91-летний математик олег ивашев-мусатов попал в отделение токсикореанимации нии имени склифосовского после того, как случайно выпил жидкость для прочистки труб «крот» — у пострадавшего диагностирован ожог пищевода и желудка. продюсер бари алибасов уже предложил его семье помощь, если она решит судиться с производителем жидкости — сам он пока безуспешно требует изменения дизайна бутылки и компенсации за лечение.\n",
      "Hyp: об обстоятельствах произошедшего рассказало издание «мк» — по его данным, поздно ночью сын математика игорь услышал со стороны ванной комнаты стоны отца — бросившись на помощь, он увидел бутылку «крота» рядом со входом в ванную. по окончании университета в 1951-м молодой математик не мог заниматься преподавательской деятельностью: дело в том, что в 1947 году под «делу даниила андреева » был арестован сергей ивашев-мусатов, и его сын был лишен такого права.\n",
      "BLEU:  0.2787700638460768\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 0/1000 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ROUGE:  {'rouge-1': {'f': 0.1622480013204, 'p': 0.13602938272392018, 'r': 0.21697324757833655}, 'rouge-2': {'f': 0.03806162855393923, 'p': 0.031322676668989094, 'r': 0.052663072956568885}, 'rouge-l': {'f': 0.12974429225357312, 'p': 0.12116853603529963, 'r': 0.1933282514913594}}\n",
      "CPU times: user 2 µs, sys: 0 ns, total: 2 µs\n",
      "Wall time: 5.72 µs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1000/1000 [3:00:32<00:00, 10.83s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Count: 1000\n",
      "Ref: 91-летний математик олег ивашев-мусатов попал в отделение токсикореанимации нии имени склифосовского после того, как случайно выпил жидкость для прочистки труб «крот» — у пострадавшего диагностирован ожог пищевода и желудка. продюсер бари алибасов уже предложил его семье помощь, если она решит судиться с производителем жидкости — сам он пока безуспешно требует изменения дизайна бутылки и компенсации за лечение.\n",
      "Hyp: однако с пятого класса олег ивашев-мусатов, мать которого после развода вышла замуж за математика андрея колмогорова , увлекся этой точной наукой. преподавателем мгу олег ивашев-мусатов стал в 1957 году, за год до того защитив кандидатскую диссертацию «о тригонометрических нуль-рядах».\n",
      "BLEU:  0.31131823269077197\n",
      "ROUGE:  {'rouge-1': {'f': 0.1524926658734175, 'p': 0.13601055968391315, 'r': 0.18551274289589859}, 'rouge-2': {'f': 0.03284741235028553, 'p': 0.029074890335201515, 'r': 0.04070736258062505}, 'rouge-l': {'f': 0.12742347923131755, 'p': 0.12213656524781268, 'r': 0.1667864095285486}}\n"
     ]
    }
   ],
   "source": [
    "calc_text_rank_score(test_records, calc_similarity=unique_words_similarity)\n",
    "calc_text_rank_score(test_records, calc_similarity=your_super_words_similarity)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "xdTrfxycB7cd"
   },
   "source": [
    "## 2 Задание: Extractive RNN (порог: 0.3 BLEU)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "6Q7DeHDYFSjX"
   },
   "source": [
    "Второй метод, который вам предлагается улучшить – поиск предложений для summary с помощью RNN. В рассмотренной методе мы использовали LSTM для генерации sentence embedding. Попробуйте использовать другие архитектуры: CNN, Transformer; или добавьте предобученные модели, как и в первом задании.\n",
    "\n",
    "P.S. Тут предполагается, что придется изменять много кода в ячееках (например, поменять токенизацию). "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "1dZamxigdEc-"
   },
   "source": [
    "### Модель\n",
    "\n",
    "Картинка для привлечения внимания:\n",
    "\n",
    "![img](https://storage.googleapis.com/groundai-web-prod/media%2Fusers%2Fuser_14%2Fproject_398421%2Fimages%2Farchitecture.png)\n",
    "\n",
    "Статья с оригинальным методом:\n",
    "https://arxiv.org/pdf/1611.04230.pdf\n",
    "\n",
    "Список вдохновения: \n",
    "- https://towardsdatascience.com/understanding-how-convolutional-neural-network-cnn-perform-text-classification-with-word-d2ee64b9dd0b Пример того, как можно применять CNN в текстовых задачах\n",
    "- https://arxiv.org/pdf/1808.08745.pdf Очень крутой метод генерации summary без Transformers\n",
    "- https://towardsdatascience.com/super-easy-way-to-get-sentence-embedding-using-fasttext-in-python-a70f34ac5b7c – простой метод генерации sentence embedding\n",
    "- https://towardsdatascience.com/fse-2b1ffa791cf9 – Необычный метод генерации sentence embedding\n",
    "- https://github.com/UKPLab/sentence-transformers – BERT предобученный для sentence embedding\n",
    "\n",
    "P.S. Выше написанные ссылки нужны только для разогрева вашей фантазии, можно воспользоваться ими, а можно придумать свой.\n",
    "\n",
    "Комментарий к заданию:\n",
    "\n",
    "Если посмотреть на архитектуру почти SummaRuNNer, то в ней есть два главных элемента: первая часть, которая читает предложения и возвращает векторы на каждое предложение, и вторая, которая выбирает предложения для суммаризации. Вторую часть мы не трогаем, а первую меняем. На что меняем – как вы решите. Главное: она должна иметь хорошее качество и встроиться в текущую модель."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 86
    },
    "colab_type": "code",
    "id": "c8ygLrHxV2y5",
    "outputId": "38274e99-4914-40cd-dea9-24a37fcbc75d"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/lib/python3.6/importlib/_bootstrap.py:219: RuntimeWarning:\n",
      "\n",
      "numpy.ufunc size changed, may indicate binary incompatibility. Expected 192 from C header, got 216 from PyObject\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from nltk.translate.bleu_score import corpus_bleu\n",
    "from rouge import Rouge\n",
    "\n",
    "def calc_scores(references, predictions, metric=\"all\"):\n",
    "    print(\"Count:\", len(predictions))\n",
    "    print(\"Ref:\", references[-1])\n",
    "    print(\"Hyp:\", predictions[-1])\n",
    "\n",
    "    if metric in (\"bleu\", \"all\"):\n",
    "        print(\"BLEU: \", corpus_bleu([[r] for r in references], predictions))\n",
    "    if metric in (\"rouge\", \"all\"):\n",
    "        rouge = Rouge()\n",
    "        scores = rouge.get_scores(predictions, references, avg=True)\n",
    "        print(\"ROUGE: \", scores)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "jXWhMdZAPHRA"
   },
   "outputs": [],
   "source": [
    "import copy\n",
    "import random\n",
    "\n",
    "import transformers\n",
    "\n",
    "import catalyst\n",
    "from catalyst.utils import set_global_seed, prepare_cudnn\n",
    "\n",
    "import math\n",
    "import razdel\n",
    "import torch\n",
    "import numpy as np\n",
    "from rouge import Rouge\n",
    "\n",
    "\n",
    "from torch.utils import data\n",
    "\n",
    "\n",
    "seed = 383\n",
    "set_global_seed(seed)\n",
    "prepare_cudnn(True)\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Sxsc0Orf8hGq"
   },
   "outputs": [],
   "source": [
    "def build_oracle_summary_greedy(text, gold_summary, calc_score, lower=True, max_sentences=30):\n",
    "    '''\n",
    "    Жадное построение oracle summary\n",
    "    '''\n",
    "    gold_summary = gold_summary.lower() if lower else gold_summary\n",
    "    # Делим текст на предложения\n",
    "    sentences = [sentence.text.lower() if lower else sentence.text for sentence in razdel.sentenize(text)][:max_sentences]\n",
    "    n_sentences = len(sentences)\n",
    "    oracle_summary_sentences = set()\n",
    "    score = -1.0\n",
    "    summaries = []\n",
    "    for _ in range(n_sentences):\n",
    "        for i in range(n_sentences):\n",
    "            if i in oracle_summary_sentences:\n",
    "                continue\n",
    "            current_summary_sentences = copy.copy(oracle_summary_sentences)\n",
    "            # Добавляем какое-то предложения к уже существующему summary\n",
    "            current_summary_sentences.add(i)\n",
    "            current_summary = \" \".join([sentences[index] for index in sorted(list(current_summary_sentences))])\n",
    "            # Считаем метрики\n",
    "            current_score = calc_score(current_summary, gold_summary)\n",
    "            summaries.append((current_score, current_summary_sentences))\n",
    "        # Если получилось улучшить метрики с добавлением какого-либо предложения, то пробуем добавить ещё\n",
    "        # Иначе на этом заканчиваем\n",
    "        best_summary_score, best_summary_sentences = max(summaries)\n",
    "        if best_summary_score <= score:\n",
    "            break\n",
    "        oracle_summary_sentences = best_summary_sentences\n",
    "        score = best_summary_score\n",
    "    oracle_summary = \" \".join([sentences[index] for index in sorted(list(oracle_summary_sentences))])\n",
    "    return oracle_summary, oracle_summary_sentences\n",
    "\n",
    "def calc_single_score(pred_summary, gold_summary, rouge):\n",
    "    return rouge.get_scores([pred_summary], [gold_summary], avg=True)['rouge-2']['f']\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 173,
     "referenced_widgets": [
      "36d571cd2137493d963efe7872843244",
      "bf0bbb6730b34366a07e60efb4f33cdf",
      "7e1c426507d245ac894007b39cb039c8",
      "1bac665cb40f4cadb60e0d0cf3684479",
      "0bc44e093afe48d289d746e2b842642a",
      "402827554257451a96dda23191a74397",
      "6a7f4d7839684348928c9551b3ce9ab5",
      "4d6145c28092410993734a0881505691"
     ]
    },
    "colab_type": "code",
    "id": "7T_ak-KDB8rp",
    "outputId": "99e1492d-0ee1-4f71-a6bf-20a3da3233b8"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "36d571cd2137493d963efe7872843244",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=1000.0), HTML(value='')))"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Count: 1000\n",
      "Ref: создатели литий-ионных батарей удостоились нобелевской премии по химии за 2019 год. трое исследователей из разных стран смогли создать источники электрического тока, которые сегодня используются во многих областях – начиная от мобильных телефонов и заканчивая электромобилями.\n",
      "Hyp: литий-ионные батареи — это быстро перезаряжаемые и мощные химические источники электрического тока, которые используются во многих областях, начиная от мобильных телефонов и заканчивая электромобилями.\n",
      "BLEU:  0.5409631965549744\n",
      "ROUGE:  {'rouge-1': {'f': 0.3721432014671718, 'p': 0.402832962982984, 'r': 0.3718899315987227}, 'rouge-2': {'f': 0.21067801623994384, 'p': 0.23438025848956512, 'r': 0.20889215894481133}, 'rouge-l': {'f': 0.3281155896920618, 'p': 0.3756051233531811, 'r': 0.3458786425968302}}\n"
     ]
    }
   ],
   "source": [
    "from tqdm.notebook import tqdm\n",
    "\n",
    "def calc_oracle_score(records, nrows=1000, lower=True):\n",
    "    references = []\n",
    "    predictions = []\n",
    "    rouge = Rouge()\n",
    "  \n",
    "    for text, summary in tqdm(records[['text', 'summary']].values[:nrows]):\n",
    "        summary = summary if not lower else summary.lower()\n",
    "        references.append(summary)\n",
    "        predicted_summary, _ = build_oracle_summary_greedy(text, summary, calc_score=lambda x, y: calc_single_score(x, y, rouge))\n",
    "        predictions.append(predicted_summary)\n",
    "\n",
    "    calc_scores(references, predictions)\n",
    "\n",
    "calc_oracle_score(test_records)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "uWgjewfWrbJZ"
   },
   "source": [
    "## (!)\n",
    "Если надо, поменяйте код загрузки токенизатора"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 54
    },
    "colab_type": "code",
    "id": "xAkZ2f5LhWwE",
    "outputId": "c1bd2e6d-b665-48d6-ed4d-7c08c96524dc"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tokenizer [['октябрь', '(', 'ж', '##ов', '##тен', '##ь', ')', 'богат', 'на', 'изменения', ',', 'как', 'никакой', 'другой', 'месяц', ',', 'сообщили', 'в', 'ГИБДД']]\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "pretrained_model_name = \"DeepPavlov/rubert-base-cased-sentence\"\n",
    "tokenizer = transformers.AutoTokenizer.from_pretrained(pretrained_model_name)\n",
    "print('tokenizer', [tokenizer.tokenize(\"октябрь (жовтень) богат на изменения, как никакой другой месяц, сообщили в ГИБДД\")])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "AOkUL_YIGp-S"
   },
   "source": [
    "## (!)\n",
    "Если надо, поменяйте код словаря"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Jdb-39jO-72q"
   },
   "outputs": [],
   "source": [
    "from rouge import Rouge\n",
    "import razdel\n",
    "\n",
    "def add_oracle_summary_to_records(records, max_sentences=30, lower=True, nrows=1000):\n",
    "    rouge = Rouge()\n",
    "    sentences_ = []\n",
    "    oracle_sentences_ = []\n",
    "    oracle_summary_ = []\n",
    "    records = records.iloc[:nrows].copy()\n",
    "\n",
    "    for text, summary in tqdm(records[['text', 'summary']].values):\n",
    "        summary = summary.lower() if lower else summary\n",
    "        sentences = [sentence.text.lower() if lower else sentence.text for sentence in razdel.sentenize(text)][:max_sentences]\n",
    "        oracle_summary, sentences_indicies = build_oracle_summary_greedy(text, summary, calc_score=lambda x, y: calc_single_score(x, y, rouge),\n",
    "                                                                         lower=lower, max_sentences=max_sentences)\n",
    "        sentences_ += [sentences]\n",
    "        oracle_sentences_ += [list(sentences_indicies)]\n",
    "        oracle_summary_ += [oracle_summary]\n",
    "    records['sentences'] = sentences_\n",
    "    records['oracle_sentences'] = oracle_sentences_\n",
    "    records['oracle_summary'] = oracle_summary_\n",
    "    return records\n",
    "\n",
    "ext_train_records = add_oracle_summary_to_records(train_records, nrows=4096)\n",
    "ext_val_records = add_oracle_summary_to_records(val_records, nrows=256)\n",
    "ext_test_records = add_oracle_summary_to_records(test_records, nrows=256)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "UlXXc8qUHC5m"
   },
   "source": [
    "## (!)\n",
    "Если надо, поменяйте код генератора датасета и батчевалки"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "MNyxstTChK3C"
   },
   "outputs": [],
   "source": [
    "import random\n",
    "import math\n",
    "import razdel\n",
    "import torch\n",
    "import numpy as np\n",
    "from rouge import Rouge\n",
    "\n",
    "\n",
    "from torch.utils import data\n",
    "\n",
    "\n",
    "class ExtDataset(data.Dataset):\n",
    "    def __init__(self, records, tokenizer, lower=True, max_sentences=30, max_sentence_length=50, device=torch.device('cpu')):\n",
    "        self.records = records\n",
    "        self.num_samples = records.shape[0]\n",
    "\n",
    "        self.tokenizer = tokenizer\n",
    "\n",
    "\n",
    "        self.lower = lower\n",
    "        self.rouge = Rouge()\n",
    "        self.max_sentences = max_sentences\n",
    "        self.max_sentence_length = max_sentence_length\n",
    "        self.device = device\n",
    "        \n",
    "    def __len__(self):\n",
    "        return self.records.shape[0]\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        cur_record = self.records.iloc[idx]\n",
    "\n",
    "        tzed = list(map(lambda x: x[:self.max_sentence_length],\n",
    "                        [self.tokenizer.tokenize(t) for t in cur_record['sentences']]))\n",
    "        encoded = list(map(lambda x: x[:self.max_sentence_length],\n",
    "                           [self.tokenizer.encode(t)[1:-1] for t in tzed]))\n",
    "\n",
    "        outputs = [int(i in cur_record['oracle_sentences']) for i in range(len(cur_record['sentences']))]\n",
    "\n",
    "        return {'inputs': encoded, 'outputs': outputs}\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "JegA9fOMsZN5"
   },
   "outputs": [],
   "source": [
    "train_dataset = ExtDataset(ext_train_records, tokenizer)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "bvARjudojEDD"
   },
   "outputs": [],
   "source": [
    "# Это батчевалка\n",
    "def collate_fn(records):\n",
    "    max_length = max(len(sentence) for record in records for sentence in record['inputs'])\n",
    "    max_sentences = max(len(record['outputs']) for record in records)\n",
    "\n",
    "    new_inputs = torch.zeros((len(records), max_sentences, max_length))\n",
    "    new_outputs = torch.zeros((len(records), max_sentences))\n",
    "    for i, record in enumerate(records):\n",
    "        for j, sentence in enumerate(record['inputs']):\n",
    "            new_inputs[i, j, :len(sentence)] += np.array(sentence)\n",
    "        new_outputs[i, :len(record['outputs'])] += np.array(record['outputs'])\n",
    "    return {'features': new_inputs.type(torch.LongTensor), 'targets': new_outputs}\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "gAMU-YJ6V2GU"
   },
   "outputs": [],
   "source": [
    "dim = 768\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 156,
     "referenced_widgets": [
      "1f139c5fe3d04143bbce52aad6efa4b2",
      "11d9552fc76a4bacb3ca0f8193dbbe9c",
      "de8e416363094a6b89b614d1b67e7c3b",
      "b7c02bff56e945f3912df12174099116",
      "f4cebb0ceea546bdbe9cde769853bc68",
      "bbcc8004460e4b40b36d5f253f2da8ac",
      "fe3a36ea59bb4c1c9a346baf4cafd4b4",
      "e8e9fc177f0f42e895c20e29f6371df9"
     ]
    },
    "colab_type": "code",
    "id": "aWlf7XdheJUN",
    "outputId": "abb1a2f9-07c3-4ca8-bf03-a2840365d858"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1f139c5fe3d04143bbce52aad6efa4b2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=711456784.0, style=ProgressStyle(descri…"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/torch/nn/modules/rnn.py:50: UserWarning:\n",
      "\n",
      "dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.3 and num_layers=1\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "\n",
    "from torch.nn.utils.rnn import pack_padded_sequence as pack\n",
    "from torch.nn.utils.rnn import pad_packed_sequence as unpack\n",
    "\n",
    "\n",
    "class YourSentenceEncoder(nn.Module):\n",
    "    # Место для вашего Sentence Encoder-а. Разрешается использовать любые методы, которые вам нравятся.\n",
    "    def __init__(self, pretrained_model_name: str, hidden_size=dim):\n",
    "        super(YourSentenceEncoder, self).__init__()\n",
    "        \n",
    "        self.hidden_size = hidden_size\n",
    "\n",
    "        self.bert = transformers.AutoModel.from_pretrained(\n",
    "            pretrained_model_name)\n",
    "        \n",
    "        for param in self.bert.parameters():\n",
    "            param.requires_grad = False\n",
    "\n",
    "        self.bert.eval()\n",
    "\n",
    "    def forward(self, inputs):\n",
    "        outputs = self.bert(inputs)[0]\n",
    "        last_hidden_states = outputs[:, 0]\n",
    "\n",
    "        return last_hidden_states\n",
    "\n",
    "\n",
    "class SentenceTaggerRNN(nn.Module):\n",
    "    def __init__(self,\n",
    "                 sentence_encoder_hidden_size=dim,\n",
    "                 hidden_size=dim,\n",
    "                 bidirectional=True,\n",
    "                 n_layers=1,\n",
    "                 dropout=0.3):\n",
    "        super(SentenceTaggerRNN, self).__init__()\n",
    "\n",
    "        num_directions = 2 if bidirectional else 1\n",
    "        assert hidden_size % num_directions == 0\n",
    "        hidden_size = hidden_size // num_directions\n",
    "\n",
    "        self.hidden_size = hidden_size\n",
    "        self.n_layers = n_layers\n",
    "        self.dropout = dropout\n",
    "        self.bidirectional = bidirectional\n",
    "\n",
    "        self.sentence_encoder = YourSentenceEncoder(\"DeepPavlov/rubert-base-cased-sentence\")\n",
    "\n",
    "        self.rnn_layer = nn.LSTM(sentence_encoder_hidden_size, hidden_size, n_layers, dropout=dropout,\n",
    "                           bidirectional=bidirectional, batch_first=True)\n",
    "        self.dropout_layer = nn.Dropout(dropout)\n",
    "        self.content_linear_layer = nn.Linear(hidden_size * 2, 1)\n",
    "        self.document_linear_layer = nn.Linear(hidden_size * 2, hidden_size * 2)\n",
    "        self.salience_linear_layer = nn.Linear(hidden_size * 2, hidden_size * 2)\n",
    "        self.tanh_layer = nn.Tanh()\n",
    "\n",
    "    def forward(self, inputs, hidden=None):\n",
    "        batch_size = inputs.size(0)\n",
    "        sentences_count = inputs.size(1)\n",
    "        tokens_count = inputs.size(2)\n",
    "        inputs = inputs.reshape(-1, tokens_count)\n",
    "        embedded_sentences = self.sentence_encoder(inputs)\n",
    "        embedded_sentences = embedded_sentences.reshape(batch_size, sentences_count, -1)\n",
    "        outputs, _ = self.rnn_layer(embedded_sentences, hidden)\n",
    "        outputs = self.dropout_layer(outputs)\n",
    "        document_embedding = self.tanh_layer(self.document_linear_layer(torch.mean(outputs, 1)))\n",
    "        content = self.content_linear_layer(outputs).squeeze(2)\n",
    "        salience = torch.bmm(outputs, self.salience_linear_layer(document_embedding).unsqueeze(2)).squeeze(2)\n",
    "        return content + salience\n",
    "\n",
    "model = SentenceTaggerRNN()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "4q2Gb6ODHHB_"
   },
   "source": [
    "### Обучение"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "zq3226mFKuYx"
   },
   "outputs": [],
   "source": [
    "# hyper parameters\n",
    "\n",
    "batch = 128\n",
    "lr = 1e-3\n",
    "num_epochs = 10\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "UVDW8raJeQxn",
    "outputId": "ed01383e-c779-4254-f076-6d5ec650fe83"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/lib/python3.6/importlib/_bootstrap.py:219: RuntimeWarning:\n",
      "\n",
      "numpy.ufunc size changed, may indicate binary incompatibility. Expected 192 from C header, got 216 from PyObject\n",
      "\n",
      "/usr/lib/python3.6/importlib/_bootstrap.py:219: RuntimeWarning:\n",
      "\n",
      "numpy.ufunc size changed, may indicate binary incompatibility. Expected 192 from C header, got 216 from PyObject\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/10 * Epoch (train): 100% 32/32 [03:45<00:00,  7.05s/it, loss=0.289]\n",
      "1/10 * Epoch (valid): 100% 2/2 [00:14<00:00,  7.02s/it, loss=0.311]\n",
      "1/10 * Epoch (test): 100% 2/2 [00:13<00:00,  6.92s/it, loss=0.311]\n",
      "[2020-05-22 16:27:11,295] \n",
      "1/10 * Epoch 1 (_base): lr=0.0010 | momentum=0.9000\n",
      "1/10 * Epoch 1 (train): loss=1.2185\n",
      "1/10 * Epoch 1 (valid): loss=0.3242\n",
      "1/10 * Epoch 1 (test): loss=0.3042\n",
      "2/10 * Epoch (train): 100% 32/32 [03:45<00:00,  7.05s/it, loss=0.249]\n",
      "2/10 * Epoch (valid): 100% 2/2 [00:13<00:00,  6.97s/it, loss=0.259]\n",
      "2/10 * Epoch (test): 100% 2/2 [00:13<00:00,  6.95s/it, loss=0.257]\n",
      "[2020-05-22 16:32:46,516] \n",
      "2/10 * Epoch 2 (_base): lr=0.0010 | momentum=0.9000\n",
      "2/10 * Epoch 2 (train): loss=0.2564\n",
      "2/10 * Epoch 2 (valid): loss=0.2682\n",
      "2/10 * Epoch 2 (test): loss=0.2538\n",
      "3/10 * Epoch (train): 100% 32/32 [03:45<00:00,  7.06s/it, loss=0.244]\n",
      "3/10 * Epoch (valid): 100% 2/2 [00:13<00:00,  6.94s/it, loss=0.251]\n",
      "3/10 * Epoch (test): 100% 2/2 [00:13<00:00,  6.94s/it, loss=0.247]\n",
      "[2020-05-22 16:38:25,108] \n",
      "3/10 * Epoch 3 (_base): lr=0.0010 | momentum=0.9000\n",
      "3/10 * Epoch 3 (train): loss=0.2442\n",
      "3/10 * Epoch 3 (valid): loss=0.2591\n",
      "3/10 * Epoch 3 (test): loss=0.2451\n",
      "4/10 * Epoch (train): 100% 32/32 [03:44<00:00,  7.02s/it, loss=0.240]\n",
      "4/10 * Epoch (valid): 100% 2/2 [00:13<00:00,  6.89s/it, loss=0.248]\n",
      "4/10 * Epoch (test): 100% 2/2 [00:13<00:00,  6.85s/it, loss=0.243]\n",
      "[2020-05-22 16:43:59,522] \n",
      "4/10 * Epoch 4 (_base): lr=0.0010 | momentum=0.9000\n",
      "4/10 * Epoch 4 (train): loss=0.2410\n",
      "4/10 * Epoch 4 (valid): loss=0.2558\n",
      "4/10 * Epoch 4 (test): loss=0.2419\n",
      "5/10 * Epoch (train): 100% 32/32 [03:44<00:00,  7.02s/it, loss=0.238]\n",
      "5/10 * Epoch (valid): 100% 2/2 [00:13<00:00,  6.92s/it, loss=0.246]\n",
      "5/10 * Epoch (test): 100% 2/2 [00:13<00:00,  6.96s/it, loss=0.241]\n",
      "[2020-05-22 16:49:32,684] \n",
      "5/10 * Epoch 5 (_base): lr=0.0010 | momentum=0.9000\n",
      "5/10 * Epoch 5 (train): loss=0.2399\n",
      "5/10 * Epoch 5 (valid): loss=0.2542\n",
      "5/10 * Epoch 5 (test): loss=0.2405\n",
      "6/10 * Epoch (train): 100% 32/32 [03:44<00:00,  7.00s/it, loss=0.239]\n",
      "6/10 * Epoch (valid): 100% 2/2 [00:13<00:00,  6.98s/it, loss=0.246]\n",
      "6/10 * Epoch (test): 100% 2/2 [00:13<00:00,  6.93s/it, loss=0.241]\n",
      "[2020-05-22 16:55:07,887] \n",
      "6/10 * Epoch 6 (_base): lr=0.0010 | momentum=0.9000\n",
      "6/10 * Epoch 6 (train): loss=0.2392\n",
      "6/10 * Epoch 6 (valid): loss=0.2535\n",
      "6/10 * Epoch 6 (test): loss=0.2404\n",
      "7/10 * Epoch (train): 100% 32/32 [03:43<00:00,  6.99s/it, loss=0.238]\n",
      "7/10 * Epoch (valid): 100% 2/2 [00:14<00:00,  7.01s/it, loss=0.245]\n",
      "7/10 * Epoch (test): 100% 2/2 [00:13<00:00,  6.94s/it, loss=0.240]\n",
      "[2020-05-22 17:00:43,588] \n",
      "7/10 * Epoch 7 (_base): lr=0.0010 | momentum=0.9000\n",
      "7/10 * Epoch 7 (train): loss=0.2385\n",
      "7/10 * Epoch 7 (valid): loss=0.2527\n",
      "7/10 * Epoch 7 (test): loss=0.2397\n",
      "8/10 * Epoch (train): 100% 32/32 [03:43<00:00,  6.98s/it, loss=0.237]\n",
      "8/10 * Epoch (valid): 100% 2/2 [00:13<00:00,  6.94s/it, loss=0.244]\n",
      "8/10 * Epoch (test): 100% 2/2 [00:13<00:00,  6.87s/it, loss=0.240]\n",
      "[2020-05-22 17:06:16,400] \n",
      "8/10 * Epoch 8 (_base): lr=0.0010 | momentum=0.9000\n",
      "8/10 * Epoch 8 (train): loss=0.2376\n",
      "8/10 * Epoch 8 (valid): loss=0.2520\n",
      "8/10 * Epoch 8 (test): loss=0.2391\n",
      "9/10 * Epoch (train): 100% 32/32 [03:42<00:00,  6.96s/it, loss=0.237]\n",
      "9/10 * Epoch (valid): 100% 2/2 [00:13<00:00,  6.87s/it, loss=0.244]\n",
      "9/10 * Epoch (test): 100% 2/2 [00:13<00:00,  6.92s/it, loss=0.240]\n",
      "[2020-05-22 17:11:48,216] \n",
      "9/10 * Epoch 9 (_base): lr=0.0010 | momentum=0.9000\n",
      "9/10 * Epoch 9 (train): loss=0.2370\n",
      "9/10 * Epoch 9 (valid): loss=0.2515\n",
      "9/10 * Epoch 9 (test): loss=0.2390\n",
      "10/10 * Epoch (train): 100% 32/32 [03:42<00:00,  6.95s/it, loss=0.235]\n",
      "10/10 * Epoch (valid): 100% 2/2 [00:13<00:00,  6.94s/it, loss=0.244]\n",
      "10/10 * Epoch (test): 100% 2/2 [00:13<00:00,  6.84s/it, loss=0.240]\n",
      "[2020-05-22 17:17:20,237] \n",
      "10/10 * Epoch 10 (_base): lr=0.0010 | momentum=0.9000\n",
      "10/10 * Epoch 10 (train): loss=0.2363\n",
      "10/10 * Epoch 10 (valid): loss=0.2512\n",
      "10/10 * Epoch 10 (test): loss=0.2390\n",
      "Top best models:\n",
      "logs/checkpoints/train.10.pth\t0.2512\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "' batch_size = 2\\n2 torch.Size([2, 30, 50])\\n1 torch.Size([60, 50])\\n11 torch.Size([60, 50, 119547])\\nlast_hidden_states.shape torch.Size([60, 119547])\\n    batch_size = 1\\n2 torch.Size([1, 30, 50])\\n1 torch.Size([30, 50])\\n11 torch.Size([30, 50, 119547])\\nlast_hidden_states.shape torch.Size([30, 119547])'"
      ]
     },
     "execution_count": 29,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import catalyst\n",
    "from catalyst.dl.runner import SupervisedRunner\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "  \n",
    "loaders = {\n",
    "    'train': data.DataLoader(ExtDataset(ext_train_records, tokenizer), batch_size=batch, collate_fn=collate_fn),\n",
    "    'valid': data.DataLoader(ExtDataset(ext_val_records, tokenizer), batch_size=batch, collate_fn=collate_fn),\n",
    "    'test': data.DataLoader(ExtDataset(ext_test_records, tokenizer), batch_size=batch, collate_fn=collate_fn),\n",
    "}\n",
    "\n",
    "optimizer  = transformers.AdamW(model.parameters(),\n",
    "                                lr=lr, betas=(0.9, 0.999), eps=1e-06,\n",
    "                                weight_decay=0.0, correct_bias=True)\n",
    "\n",
    "criterion = nn.BCEWithLogitsLoss()\n",
    "runner = SupervisedRunner()\n",
    "runner.train(\n",
    "    model=model,\n",
    "    optimizer=optimizer,\n",
    "    loaders=loaders,\n",
    "    logdir='./logs',\n",
    "    num_epochs=num_epochs,\n",
    "    criterion=criterion,\n",
    "    verbose=True\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 173,
     "referenced_widgets": [
      "1963eb8cce0c4d4a8ccc5b983e1434f8",
      "92405d78a4834f0297c3794bb929e16e",
      "83cabb1207874da8acec2c336c40876b",
      "cd0cfe021c3f453cbb313c478de5e726",
      "33686e0c16774bf3aed38e085aec6d63",
      "c4f6d96cdc5e447186540fc4ba836b9e",
      "d52a7231501b41349b3d78957c888c76",
      "a5a3acb0bee64c9fbb7705eced8d801c"
     ]
    },
    "colab_type": "code",
    "id": "EwqhK2dyKuGL",
    "outputId": "a9c020a6-61cd-40f0-9389-bbca49ce4b3c"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1963eb8cce0c4d4a8ccc5b983e1434f8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=256.0), HTML(value='')))"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Count: 256\n",
      "Ref: региональное управление следственного комитета по алтайскому краю начало доследственную проверку жалобы жительницы села санниково дмитрию медведеву — на сегодняшней встрече она рассказала премьеру, что в ее доме вот уже 15 лет нет горячей воды. местные власти оправдываются отсутствием денег на ремонт котельной — но теперь обещают решить проблему.\n",
      "Hyp: в алтайском крае следователи начали доследственную проверку из-за обращения жительницы села санниково к премьер-министру дмитрию медведеву. глава правительства приехал в регион, чтобы провести совещание по улучшению качества жизни сельских жителей. у порога дома культуры, где проходило заседание, его ждали жители санниково — среди них была женщина, которая решила обратиться к медведеву с просьбой о помощи.\n",
      "BLEU:  0.4804895006406047\n",
      "ROUGE:  {'rouge-1': {'f': 0.27484234174401534, 'p': 0.29272952798335183, 'r': 0.28305522589824017}, 'rouge-2': {'f': 0.12899945478325076, 'p': 0.13532967212826197, 'r': 0.13662181524840314}, 'rouge-l': {'f': 0.23258363421786304, 'p': 0.264281715041889, 'r': 0.2559170038047647}}\n"
     ]
    }
   ],
   "source": [
    "references = []\n",
    "predictions = []\n",
    "model.eval()\n",
    "for i, item in tqdm(enumerate(data.DataLoader(ExtDataset(ext_test_records, tokenizer), batch_size=1, collate_fn=collate_fn)), total=ext_test_records.shape[0]):\n",
    "    logits = model(item[\"features\"].to(device))[0] # Прямой проход\n",
    "    record = ext_test_records.iloc[i]\n",
    "    predicted_summary = []\n",
    "    for i, logit in enumerate(logits):\n",
    "        if logit > -1.365:\n",
    "            predicted_summary.append(record['sentences'][i])\n",
    "    if not predicted_summary:\n",
    "        predicted_summary.append(record['sentences'][torch.max(logits, dim=0)[1].item()])\n",
    "    predicted_summary = \" \".join(predicted_summary)\n",
    "    references.append(record['summary'].lower())\n",
    "    predictions.append(predicted_summary)\n",
    "\n",
    "calc_scores(references, predictions)\n"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "[homework]TextSummarization_20.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "187731a5070d48c9a963da3553d8b1c6": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": "initial"
     }
    },
    "1a6241e1bddd4889b29aaa487108d99a": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_4356a6a39fb64fbba42ec6a7373cc666",
       "IPY_MODEL_ca11129007c846faba5aa6eddf246c8b"
      ],
      "layout": "IPY_MODEL_adad49b14a3846a6a58bf6da21eed356"
     }
    },
    "1cfbfdb3ed4846c8bf3c9627d2030e4a": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "Downloading: 100%",
      "description_tooltip": null,
      "layout": "IPY_MODEL_b28d3502559b498f8dc9c6a91e30b29f",
      "max": 711456784,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_9d7e701f928041a6b7552c41f791f483",
      "value": 711456784
     }
    },
    "207f17d2d4b14a3ea2152d7f218178e5": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "2833541725a94c25969a3577cc530e24": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "28daeb2fc17c4428b3f23a195b0b3c8c": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "3cbb33ac3a4b4759b1ee0dce6c7ff0ad": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "4356a6a39fb64fbba42ec6a7373cc666": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "Downloading: 100%",
      "description_tooltip": null,
      "layout": "IPY_MODEL_8745e42d4987443a85813077bc68b675",
      "max": 112,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_187731a5070d48c9a963da3553d8b1c6",
      "value": 112
     }
    },
    "44defe717cf747fe9f330841a8388a78": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "4631e9af312e4bc9b91287a4312ca5c8": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_af9cfb21b60f4e13a309ef108693d88e",
      "placeholder": "​",
      "style": "IPY_MODEL_e43aec4ccb594486bf3eade8d89b7b2f",
      "value": " 1.65M/1.65M [00:01&lt;00:00, 971kB/s]"
     }
    },
    "476e4553b28641f799db9704d2dbbe25": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": "initial"
     }
    },
    "510ba48686a5409d978c5476538a4949": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "Downloading: 100%",
      "description_tooltip": null,
      "layout": "IPY_MODEL_a54684bc3a1249488dcfc8c502afea11",
      "max": 642,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_db078a74d1994f53973fa06af7ce8981",
      "value": 642
     }
    },
    "52f5c0a6764843c1ab94aaae1ab141c0": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_510ba48686a5409d978c5476538a4949",
       "IPY_MODEL_e8c0c6b9322444d3a0eea04b25729c28"
      ],
      "layout": "IPY_MODEL_207f17d2d4b14a3ea2152d7f218178e5"
     }
    },
    "5a93df56b1814b918805d4afb68f8745": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "Downloading: 100%",
      "description_tooltip": null,
      "layout": "IPY_MODEL_d161a3f94d61497a847c2387351c4d82",
      "max": 1649718,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_8ca17c2bf19147738fd3c7b57e355315",
      "value": 1649718
     }
    },
    "603320f156a54ac1b62d916b101b7f6d": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_677699f9452148afb9a906766c59984e",
      "placeholder": "​",
      "style": "IPY_MODEL_c5e44a8d4b4b45b9a8c61fc957bbdb1b",
      "value": " 24.0/24.0 [00:00&lt;00:00, 127B/s]"
     }
    },
    "677699f9452148afb9a906766c59984e": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "73bd49f2621e4629a4fc896079a4cc76": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_1cfbfdb3ed4846c8bf3c9627d2030e4a",
       "IPY_MODEL_7412c847046645159e89a186b2df6d0a"
      ],
      "layout": "IPY_MODEL_44defe717cf747fe9f330841a8388a78"
     }
    },
    "7412c847046645159e89a186b2df6d0a": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_81785dd999c24fbd89a98b04ed5c5d37",
      "placeholder": "​",
      "style": "IPY_MODEL_3cbb33ac3a4b4759b1ee0dce6c7ff0ad",
      "value": " 711M/711M [00:47&lt;00:00, 14.9MB/s]"
     }
    },
    "81785dd999c24fbd89a98b04ed5c5d37": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "8745e42d4987443a85813077bc68b675": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "8ca17c2bf19147738fd3c7b57e355315": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": "initial"
     }
    },
    "9d7e701f928041a6b7552c41f791f483": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": "initial"
     }
    },
    "a54684bc3a1249488dcfc8c502afea11": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "a8202956ebf64de9a69c11b6ef7ecd23": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_5a93df56b1814b918805d4afb68f8745",
       "IPY_MODEL_4631e9af312e4bc9b91287a4312ca5c8"
      ],
      "layout": "IPY_MODEL_add6c0103cff42a295f4ee4d914e0c0d"
     }
    },
    "adad49b14a3846a6a58bf6da21eed356": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "add6c0103cff42a295f4ee4d914e0c0d": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "af9cfb21b60f4e13a309ef108693d88e": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "b28d3502559b498f8dc9c6a91e30b29f": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "b6f52783e7ad4260a62b83a4180b0096": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "c5e44a8d4b4b45b9a8c61fc957bbdb1b": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "c663e3433edf4bddbab170c965c0bc8d": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "Downloading: 100%",
      "description_tooltip": null,
      "layout": "IPY_MODEL_28daeb2fc17c4428b3f23a195b0b3c8c",
      "max": 24,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_476e4553b28641f799db9704d2dbbe25",
      "value": 24
     }
    },
    "ca11129007c846faba5aa6eddf246c8b": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_2833541725a94c25969a3577cc530e24",
      "placeholder": "​",
      "style": "IPY_MODEL_b6f52783e7ad4260a62b83a4180b0096",
      "value": " 112/112 [00:00&lt;00:00, 116B/s]"
     }
    },
    "cf02a69dd113471fa5dbbcd3a78712b1": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "d161a3f94d61497a847c2387351c4d82": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "db078a74d1994f53973fa06af7ce8981": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": "initial"
     }
    },
    "e43aec4ccb594486bf3eade8d89b7b2f": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "e5138e7a20394f3f8aba4a47a0dc32d5": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "e8c0c6b9322444d3a0eea04b25729c28": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_e5138e7a20394f3f8aba4a47a0dc32d5",
      "placeholder": "​",
      "style": "IPY_MODEL_cf02a69dd113471fa5dbbcd3a78712b1",
      "value": " 642/642 [00:02&lt;00:00, 250B/s]"
     }
    },
    "e9dbceb0226e48fd8e082f30d5b74598": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "f6588cb521f1475993791d73339089f5": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_c663e3433edf4bddbab170c965c0bc8d",
       "IPY_MODEL_603320f156a54ac1b62d916b101b7f6d"
      ],
      "layout": "IPY_MODEL_e9dbceb0226e48fd8e082f30d5b74598"
     }
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
